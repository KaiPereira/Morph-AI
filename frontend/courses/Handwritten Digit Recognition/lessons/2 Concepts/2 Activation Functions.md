# Introduction

Welcome to this lesson on activation functions! 

Activation functions are a crucial component of neural networks as they introduce non-linearity and allow the network to learn complex patterns from the input data. 

In this lesson, we will explore different types of activation functions, their properties, and their role in neural networks. Let's get started!

## What are Activation Functions

Activation functions are simply a function added into a neural network to help it learn!

- Activation functions are mathematical functions that introduce non-linearity into neural networks, allowing them to learn complex patterns from data.

- Neural networks use activation functions to transform the outputs of individual neurons into the inputs for the next layer of neurons.

- Activation functions help neural networks make decisions by determining whether a neuron should be "activated" or "fired" based on its input.

## Importance of Activation Functions

Activation functions are really important in neural networks. Here are some aspects:

- Without activation functions, neural networks would essentially be just linear models, which are limited in their ability to learn complex patterns from data.

- Activation functions allow neural networks to model complex relationships between inputs and outputs, making them powerful tools for tasks like image recognition, speech recognition, and natural language processing.

- The choice of activation function can have a significant impact on the performance and convergence of a neural network, and different activation functions may be more suitable for different tasks or network architectures.

## How they works

- **Activation functions take an input value, apply a mathematical operation to it, and produce an output value.**

- The output value is determined by the properties of the activation function. For example, the sigmoid function squashes input values to a range between 0 and 1, while the ReLU function only activates neurons with positive inputs.

- Activation functions help neural networks learn complex patterns from data by introducing non-linearity. Without activation functions, neural networks would be limited to learning only linear relationships, which may not be sufficient for many real-world problems.